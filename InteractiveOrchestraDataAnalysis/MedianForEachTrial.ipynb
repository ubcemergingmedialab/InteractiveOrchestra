{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a script for finding the median Velocity Magnitude in the first region of the prep beat!\n",
    "# We define the first region as everything leading up to the point of highest altitude, that is the max value in Position_Y\n",
    "# The output will be a table with only four features: Trial, BPM, GestureSize, and MedianVelocityRegionOne\n",
    "# Much like in the tutorial document, the first step is to import all of the libraries we're going to need. \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we grab the data csv file from wherever it's saved. If your script is in the same directory as the csv, the following line will do\n",
    "data = pd.read_csv(r'CleanData.csv');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives us an array of 1 through 40 \n",
    "trials = range(1,41)\n",
    "bpm = [80,100,120]\n",
    "gestureSize = [\"S\",\"M\",\"L\"]\n",
    "# We initialize these array because we're going to be iterating over them in a bit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lines let Python know that we want to treat the data as numbers, not strings\n",
    "# This will be useful when we're splicing the data set and comparing values\n",
    "data.DistanceCoveredSoFar = data.DistanceCoveredSoFar.astype(float)\n",
    "data.VelocityMagnitude = data.VelocityMagnitude.astype(float)\n",
    "data.AngleToBP1 = data.AngleToBP1.astype(float)\n",
    "data.BPM = data.BPM.astype(int)\n",
    "data.Position_Y = data.Position_Y.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define how we want our final table to look like. \n",
    "# We name all our features\n",
    "newOutputTable = pd.DataFrame({'Trial':[],'BPM':[],'GestureSize':[],'MedianVelocityRegionOne':[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's where we iterate over the arrays we mentioned earlier\n",
    "for g in gestureSize:\n",
    "    for b in bpm:\n",
    "        for i in trials:\n",
    "            # First we slice, by only getting the ith trial\n",
    "            sliceByTrial = data.loc[data.Trial == i]\n",
    "            #Then we slice by getting only gesture g, of trial i\n",
    "            sliceByGesture = sliceByTrial.loc[sliceByTrial.GestureSize == g]\n",
    "            #Then we slice by getting only bpm b, of gesture g and trial i\n",
    "            sliceByBPM = sliceByGesture.loc[sliceByGesture.BPM == b]\n",
    "            \n",
    "            # Now we need to find the index where the position is highest\n",
    "            # T his will correspond to the moment of the prep beat, right before the user moves downwards towards the base plane\n",
    "            # idxmax() is a built in python function that grabs the index of the max value of a given array\n",
    "            globalHighestPointIndex = sliceByBPM.Position_Y.idxmax()\n",
    "            \n",
    "            # The next operation exists because 'globalHighestPointIndex' will give us the index of the highest position, in terms of the indexing of the entire dataset\n",
    "            # So although our now spliced data stored in 'sliceByBPM' has only about 40 data points, we might be getting an index of 6000 or something crazy.\n",
    "            # The reason this is cumbersome is because, a few lines below, we're going to be slicing this dataset from 0 to our 'globalHighestPointIndex'\n",
    "            # Getting the data points from 0 to 6000 doesn't make sense for a 40 data point dataset. So we want a 'local' 'HighestPointIndex'\n",
    "            \n",
    "            # We subtract 'globalHighestPointIndex' by the index of the very first data point in 'sliceByBPM'.\n",
    "            # This gives us the number of items between highestPointIndex and the beginning of the gesture. \n",
    "            # We then add 1 because of how arrays work. That is, array[5] for example gives us the item at index 4. \n",
    "            # localHighestPointIndex is now the index at which the highest Position_Y is stored within the 'sliceByBPM' dataset\n",
    "            localHighestPointIndex = globalHighestPointIndex - sliceByBPM.index[0] + 1\n",
    "            \n",
    "            # Finally we can get the median by using the np.median function on the now sliced 'sliceByBPM' set\n",
    "            currentMedianVelocity = np.median(sliceByBPM[0:localHighestPointIndex].VelocityMagnitude)\n",
    "            \n",
    "            # Finally we use the 'pandas' append function to add some data to the table we started creating earlier. \n",
    "            newOutputTable = newOutputTable.append({'Trial': i,'BPM':b,'GestureSize':g,'MedianVelocityRegionOne':currentMedianVelocity}, ignore_index = True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now if we run this cell, we cann see that we've created a new table, now with more condensed information\n",
    "newOutputTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(newOutputTable[newOutputTable.GestureSize == \"S\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(newOutputTable[newOutputTable.GestureSize == \"M\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(newOutputTable[newOutputTable.GestureSize == \"L\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These last three lines are just for fun. We can see that the median velocity definitely increases with size! \n",
    "# Now let's go get more data! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When you're done with your data set, save it as a csv and push it up to develop. \n",
    "# Once we have all of the data we need, we'll combine it all into one table and start messing around with the values. \n",
    "newOutputTable.to_csv(r'MedianVelocityRegionOne.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
